{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "from cesium.time_series import TimeSeries\n",
    "import cesium.featurize as featurize\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import schwimmbad\n",
    "\n",
    "#typically I use pandas, but it doesn't conform to the code used for starting up :) \n",
    "from astropy.table import Table\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Table.read('../data/training_set.csv',format='csv')\n",
    "#meta_data = pd.read_csv('../data/training_set_metadata.csv')\n",
    "meta_data = Table.read('../data/training_set_metadata.csv', format='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682b552cf9154dcc9b5ed49637bdd8f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbmap = OrderedDict([(0,'u'), (1,'g'), (2,'r'), (3,'i'), (4, 'z'), (5, 'y')])\n",
    "\n",
    "# it also helps to have passbands associated with a color\n",
    "pbcols = OrderedDict([(0,'blueviolet'), (1,'green'), (2,'red'),\\\n",
    "                      (3,'orange'), (4, 'black'), (5, 'brown')])\n",
    "\n",
    "pbnames = list(pbmap.values())\n",
    "\n",
    "\n",
    "lcdata = data  #light curve data\n",
    "nobjects = len(meta_data)  #number of sources\n",
    "\n",
    "tsdict = OrderedDict()  #create a dictionary for each time series\n",
    "for i in tnrange(nobjects, desc='Building Timeseries'): #descending order\n",
    "    row = meta_data[i]\n",
    "    thisid = row['object_id']\n",
    "    target = row['target']\n",
    "    \n",
    "    meta = {'z':row['hostgal_photoz'],\\\n",
    "            'zerr':row['hostgal_photoz_err'],\\\n",
    "            'mwebv':row['mwebv']}\n",
    "    \n",
    "    ind = (lcdata['object_id'] == thisid)\n",
    "    thislc = lcdata[ind]\n",
    "\n",
    "    pbind = [(thislc['passband'] == pb) for pb in pbmap]  #mask individual passpands\n",
    "    t = [thislc['mjd'][mask].data for mask in pbind ]  # mask of times for specific passband\n",
    "    m = [thislc['flux'][mask].data for mask in pbind ] #mask of flux at the same times for this passband\n",
    "    e = [thislc['flux_err'][mask].data for mask in pbind ] #mask for flux errors for this passband\n",
    "\n",
    "    tsdict[thisid] = TimeSeries(t=t, m=m, e=e,\\\n",
    "                        label=target, name=thisid, meta_features=meta,\\\n",
    "                        channel_names=pbnames )\n",
    "    \n",
    "del lcdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I want to create recurrent sequences of the same length, so will try and identify the variations in length of flux measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7848"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding!  63\n",
      "615\n",
      "Ding ding!  70\n",
      "713\n",
      "Ding ding!  72\n",
      "730\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i,src in enumerate(tsdict):\n",
    "    for j,_ in enumerate(tsdict[src].measurement):\n",
    "        val = len(tsdict[src].measurement[j]) \n",
    "       # print(val)\n",
    "        if val > max_len:\n",
    "            print(\"Ding ding! \" ,val)\n",
    "            max_len = val\n",
    "            print(src)\n",
    "            src_max = src\n",
    "            pband_max = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pband_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: The maximum number of measurements of any given source is 72 measurements, meaning all other arrays need to match this length. In NLP research, I've called this \"padding\", so I will do the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nHow it was done previously, will apply this function when ready. \\npad = 'pre' #pad in the beginning, reasoning explained earlier. \\n\\nX_train_pad = pad_sequences(X_train_tokens, maxlen=max_tokens,\\n                            padding=pad, truncating=pad)\\n\\n\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "How it was done previously, will apply this function when ready. \n",
    "pad = 'pre' #pad in the beginning, reasoning explained earlier. \n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan iterate through each sequence, and prepad like before to make them 72 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,1,3,423,4],[2,3]])  #arrange the sequences like this, do for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   1,   3, 423,   4],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   2,   3]], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences(X,maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            6,    39,   -10,   -65,  -113,   -68,   -97,   -97,  -108,\n",
       "         -116,  -102,   -52,    55,  -107,   -88,   -50,    50,   110,\n",
       "          120,   111,   -49,   -87,   100,    86,    82,    41,     9,\n",
       "          -83,   108,     6,   -35,   -52,   108,   125,   107,    61,\n",
       "           -9,   106,    67,    24,   -15,    89,   118,    82,    49,\n",
       "            9,   -30,  -101,  -110,  -114,   -51,    20,   -24,   -63,\n",
       "         -101,  -110,  -113,  -110,   -89,   -10,    99,   120,   121],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -816, -1061,  -815,  -820,\n",
       "         -921,  -449,    35,   129,  -420,  -527, -1100,  -178,  -953,\n",
       "        -1003,   217,   646,  -942,  -910,   659,   -98,  -437,  -743,\n",
       "         -878,  -917,   -62,  -836, -1077,  -339, -1028,   276,   650,\n",
       "        -1094,  -370, -1086,   346,   356, -1098,    14,   660,  -624,\n",
       "        -1031,   -32,   566, -1084,    51,   142, -1076,  -972,  -812,\n",
       "         -963,   655,   205,  -388,    70,   457,  -537,  -607,   607],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -544,  -681,  -548,  -554,\n",
       "         -630,  -280,   391,   168,  -256,  -342,  -678,   -54,  -639,\n",
       "         -502,   459,   599,  -637,  -332,   604,     4,  -274,  -491,\n",
       "         -588,  -322,    31,  -568,  -628,  -180,  -555,   469,   607,\n",
       "         -672,   208,  -648,   491,   341,  -676,    85,   611,  -408,\n",
       "         -680,   365,   510,  -664,   113,   178,  -629,  -447,  -143,\n",
       "         -425,   586,   226,  -224,   404,   422,  -355,    56,   552],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -471,  -524,  -475,  -477,\n",
       "         -518,  -316,   330,    30,  -298,  -363,  -506,  -140,  -518,\n",
       "         -233,   361,   354,  -524,   -62,   373,   -93,  -310,  -449,\n",
       "         -495,   -52,   -72,  -483,  -421,  -249,  -306,   374,   365,\n",
       "         -503,   269,  -455,   384,   153,  -511,   -24,   386,  -405,\n",
       "         -530,   319,   271,  -488,    -4,    41,  -435,  -176,    86,\n",
       "         -148,   445,    73,  -274,   338,   205,  -372,   208,   296],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -388,  -393,  -405,  -400,\n",
       "         -422,  -332,   360,   -60,  -311,  -348,  -304,  -200,  -418,\n",
       "          111,   374,   293,  -414,   202,   322,  -165,  -317,  -393,\n",
       "         -417,   205,  -151,  -409,   -93,  -275,    49,   374,   305,\n",
       "         -284,   326,  -145,   381,    52,  -347,  -111,   325,  -371,\n",
       "         -406,   360,   204,  -222,   -96,   -52,  -111,   140,   257,\n",
       "          161,   361,   -19,  -292,   362,   123,  -350,   297,   235],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,  -355,  -421,  -415,\n",
       "         -422,  -365,   369,  -128,  -344,  -391,  -187,  -263,  -418,\n",
       "          206,   370,   232,  -408,   270,   263,  -233,  -351,  -406,\n",
       "         -413,   269,  -216,  -412,    31,  -330,   154,   363,   256,\n",
       "         -176,   358,     2,   378,   -19,  -240,  -180,   280,  -395,\n",
       "         -358,   370,   128,   -85,  -175,  -112,    30,   228,   302,\n",
       "          238,   328,   -83,  -354,   378,    33,  -371,   332,   157]], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences(tsdict[615].measurement,maxlen=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   6.878784,   39.364853,  -10.422381,  -65.48513 , -113.349159,\n",
       "         -68.502457,  -97.353195,  -97.52388 , -108.672577, -116.913223,\n",
       "        -102.768921,  -52.407089,   55.567715, -107.080536,  -88.981155,\n",
       "         -50.179337,   50.00864 ,  110.753555,  120.867218,  111.464226,\n",
       "         -49.905262,  -87.160583,  100.12928 ,   86.776741,   82.078186,\n",
       "          41.947815,    9.061676,  -83.072884,  108.483109,    6.768485,\n",
       "         -35.14933 ,  -52.922794,  108.020546,  125.182808,  107.64978 ,\n",
       "          61.068066,   -9.100937,  106.447296,   67.234062,   24.868933,\n",
       "         -15.392517,   89.070496,  118.935989,   82.168922,   49.886921,\n",
       "           9.075453,  -30.764908, -101.419899, -110.688477, -114.774445,\n",
       "         -51.614189,   20.364273,  -24.682575,  -63.5466  , -101.81929 ,\n",
       "        -110.978699, -113.588432, -110.649872,  -89.973892,  -10.015225,\n",
       "          99.438087,  120.849113,  121.411896]),\n",
       " array([ -816.434326, -1061.457031,  -815.188599,  -820.042786,\n",
       "         -921.002502,  -449.095612,    35.511822,   129.541901,\n",
       "         -420.796417,  -527.020325, -1100.440063,  -178.149399,\n",
       "         -953.883728, -1003.971497,   217.894211,   646.523193,\n",
       "         -942.167908,  -910.677734,   659.486694,   -98.796974,\n",
       "         -437.42511 ,  -743.267212,  -878.043396,  -917.875488,\n",
       "          -62.120552,  -836.233154, -1077.3479  ,  -339.875153,\n",
       "        -1028.441528,   276.757751,   650.984314, -1094.027588,\n",
       "         -370.189575, -1086.77771 ,   346.335083,   356.63269 ,\n",
       "        -1098.651489,    14.526012,   660.626343,  -624.518799,\n",
       "        -1031.102905,   -32.986282,   566.281433, -1084.891113,\n",
       "           51.060081,   142.089966, -1076.6521  ,  -972.201111,\n",
       "         -812.792908,  -963.21698 ,   655.284058,   205.029755,\n",
       "         -388.231476,    70.494507,   457.502197,  -537.169312,\n",
       "         -607.040771,   607.047668]),\n",
       " array([-544.810303, -681.858887, -548.01355 , -554.903198, -630.523682,\n",
       "        -280.03952 ,  391.399231,  168.739899, -256.66098 , -342.819763,\n",
       "        -678.045715,  -54.94949 , -639.03595 , -502.215332,  459.452667,\n",
       "         599.812195, -637.105347, -332.763123,  604.344543,    4.656033,\n",
       "        -274.711029, -491.146423, -588.397949, -322.420471,   31.499735,\n",
       "        -568.408875, -628.32135 , -180.729568, -555.853943,  469.654999,\n",
       "         607.786804, -672.681335,  208.281052, -648.682312,  491.748383,\n",
       "         341.057709, -676.669189,   85.162651,  611.984558, -408.570984,\n",
       "        -680.489441,  365.607056,  510.690094, -664.729675,  113.021248,\n",
       "         178.624359, -629.010254, -447.68158 , -143.843872, -425.988464,\n",
       "         586.178345,  226.696259, -224.917938,  404.391388,  422.610779,\n",
       "        -355.611389,   56.559818,  552.150269]),\n",
       " array([-471.385529, -524.95459 , -475.516052, -477.00473 , -518.533997,\n",
       "        -316.704865,  330.623901,   30.120724, -298.936859, -363.282532,\n",
       "        -506.687408, -140.818436, -518.293274, -233.167755,  361.023438,\n",
       "         354.961365, -524.586548,  -62.06501 ,  373.986511,  -93.73288 ,\n",
       "        -310.010925, -449.714752, -495.472015,  -52.056461,  -72.958771,\n",
       "        -483.071381, -421.859406, -249.205673, -306.2005  ,  374.669556,\n",
       "         365.408752, -503.870422,  269.200806, -455.588196,  384.185303,\n",
       "         153.004929, -511.148254,  -24.350578,  386.31192 , -405.614258,\n",
       "        -530.644592,  319.249847,  271.66391 , -488.010925,   -4.268328,\n",
       "          41.418739, -435.558533, -176.163651,   86.606873, -148.178238,\n",
       "         445.737061,   73.38472 , -274.108429,  338.994537,  205.937546,\n",
       "        -372.485565,  208.770279,  296.946533]),\n",
       " array([-388.984985, -393.480225, -405.663818, -400.270386, -422.184509,\n",
       "        -332.885437,  360.397858,  -60.942333, -311.977783, -348.628662,\n",
       "        -304.049713, -200.294128, -418.723907,  111.507675,  374.446442,\n",
       "         293.879608, -414.447723,  202.288223,  322.604034, -165.793457,\n",
       "        -317.63092 , -393.971649, -417.145325,  205.180893, -151.126511,\n",
       "        -409.470642,  -93.729095, -275.762329,   49.555847,  374.948822,\n",
       "         305.33075 , -284.747498,  326.272308, -145.305023,  381.953735,\n",
       "          52.912033, -347.090027, -111.062698,  325.401184, -371.286377,\n",
       "        -406.733521,  360.507599,  204.409866, -222.254257,  -96.020035,\n",
       "         -52.46059 , -111.499573,  140.860611,  257.570221,  161.872543,\n",
       "         361.595764,  -19.212976, -292.55899 ,  362.88855 ,  123.04821 ,\n",
       "        -350.518677,  297.624725,  235.489929]),\n",
       " array([-355.88678 , -421.199066, -415.286896, -422.815094, -365.075775,\n",
       "         369.439667, -128.920334, -344.536072, -391.271271, -187.285919,\n",
       "        -263.57843 , -418.799927,  206.425323,  370.346283,  232.535995,\n",
       "        -408.089233,  270.584869,  263.481476, -233.501724, -351.278198,\n",
       "        -406.549103, -413.673431,  269.709167, -216.914032, -412.820221,\n",
       "          31.207939, -330.891327,  154.876785,  363.130493,  256.966217,\n",
       "        -176.409851,  358.320099,    2.939076,  378.118225,  -19.384567,\n",
       "        -240.316895, -180.234787,  280.721069, -395.406128, -358.87616 ,\n",
       "         370.305267,  128.521851,  -85.524307, -175.912643, -112.286079,\n",
       "          30.267401,  228.033112,  302.167328,  238.576889,  328.836731,\n",
       "         -83.394951, -354.07428 ,  378.188141,   33.726837, -371.87323 ,\n",
       "         332.919006,  157.0802  ])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsdict[615].measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,src in enumerate(tsdict):\n",
    "    tsdict[src].measurement = pad_sequences(tsdict[src].measurement,maxlen=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsdict[615].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            6,    39,   -10,   -65,  -113,   -68,   -97,   -97,  -108,\n",
       "         -116,  -102,   -52,    55,  -107,   -88,   -50,    50,   110,\n",
       "          120,   111,   -49,   -87,   100,    86,    82,    41,     9,\n",
       "          -83,   108,     6,   -35,   -52,   108,   125,   107,    61,\n",
       "           -9,   106,    67,    24,   -15,    89,   118,    82,    49,\n",
       "            9,   -30,  -101,  -110,  -114,   -51,    20,   -24,   -63,\n",
       "         -101,  -110,  -113,  -110,   -89,   -10,    99,   120,   121],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -816, -1061,  -815,  -820,\n",
       "         -921,  -449,    35,   129,  -420,  -527, -1100,  -178,  -953,\n",
       "        -1003,   217,   646,  -942,  -910,   659,   -98,  -437,  -743,\n",
       "         -878,  -917,   -62,  -836, -1077,  -339, -1028,   276,   650,\n",
       "        -1094,  -370, -1086,   346,   356, -1098,    14,   660,  -624,\n",
       "        -1031,   -32,   566, -1084,    51,   142, -1076,  -972,  -812,\n",
       "         -963,   655,   205,  -388,    70,   457,  -537,  -607,   607],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -544,  -681,  -548,  -554,\n",
       "         -630,  -280,   391,   168,  -256,  -342,  -678,   -54,  -639,\n",
       "         -502,   459,   599,  -637,  -332,   604,     4,  -274,  -491,\n",
       "         -588,  -322,    31,  -568,  -628,  -180,  -555,   469,   607,\n",
       "         -672,   208,  -648,   491,   341,  -676,    85,   611,  -408,\n",
       "         -680,   365,   510,  -664,   113,   178,  -629,  -447,  -143,\n",
       "         -425,   586,   226,  -224,   404,   422,  -355,    56,   552],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -471,  -524,  -475,  -477,\n",
       "         -518,  -316,   330,    30,  -298,  -363,  -506,  -140,  -518,\n",
       "         -233,   361,   354,  -524,   -62,   373,   -93,  -310,  -449,\n",
       "         -495,   -52,   -72,  -483,  -421,  -249,  -306,   374,   365,\n",
       "         -503,   269,  -455,   384,   153,  -511,   -24,   386,  -405,\n",
       "         -530,   319,   271,  -488,    -4,    41,  -435,  -176,    86,\n",
       "         -148,   445,    73,  -274,   338,   205,  -372,   208,   296],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  -388,  -393,  -405,  -400,\n",
       "         -422,  -332,   360,   -60,  -311,  -348,  -304,  -200,  -418,\n",
       "          111,   374,   293,  -414,   202,   322,  -165,  -317,  -393,\n",
       "         -417,   205,  -151,  -409,   -93,  -275,    49,   374,   305,\n",
       "         -284,   326,  -145,   381,    52,  -347,  -111,   325,  -371,\n",
       "         -406,   360,   204,  -222,   -96,   -52,  -111,   140,   257,\n",
       "          161,   361,   -19,  -292,   362,   123,  -350,   297,   235],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,  -355,  -421,  -415,\n",
       "         -422,  -365,   369,  -128,  -344,  -391,  -187,  -263,  -418,\n",
       "          206,   370,   232,  -408,   270,   263,  -233,  -351,  -406,\n",
       "         -413,   269,  -216,  -412,    31,  -330,   154,   363,   256,\n",
       "         -176,   358,     2,   378,   -19,  -240,  -180,   280,  -395,\n",
       "         -358,   370,   128,   -85,  -175,  -112,    30,   228,   302,\n",
       "          238,   328,   -83,  -354,   378,    33,  -371,   332,   157]], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsdict[615].measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So again taking another baby step. Right now I recognize I am still not retaining the importance of how the datapoints taken are not evenly spaced, and because of this the time value should also be attached. But for now I am ignoring that, and will try and apply a recurrent neural net to this data as it stands, where each input is 6 sequences, with a label of one of those 14/15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for  src in tsdict:\n",
    "    X.append(tsdict[src].measurement[0]) #fuck it, only looking at one filter and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 72)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    6,   39,\n",
       "        -10,  -65, -113,  -68,  -97,  -97, -108, -116, -102,  -52,   55,\n",
       "       -107,  -88,  -50,   50,  110,  120,  111,  -49,  -87,  100,   86,\n",
       "         82,   41,    9,  -83,  108,    6,  -35,  -52,  108,  125,  107,\n",
       "         61,   -9,  106,   67,   24,  -15,   89,  118,   82,   49,    9,\n",
       "        -30, -101, -110, -114,  -51,   20,  -24,  -63, -101, -110, -113,\n",
       "       -110,  -89,  -10,   99,  120,  121], dtype=int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] #this is the first input, and as a result I am submitting a 3d tensor, where there are 6 channels for each filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in the labels already lined up \n",
    "\n",
    "featurefile = '../data/plasticc_featuretable.npz'\n",
    "if os.path.exists(featurefile):\n",
    "    featuretable, _ = featurize.load_featureset(featurefile)\n",
    "else:\n",
    "    print(\"Load this back!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_names = featuretable.columns.values\n",
    "new_names = ['{}_{}'.format(x, pbmap.get(y,'meta')) for x,y in old_names]\n",
    "cols = [featuretable[col] for col in old_names]\n",
    "allfeats = Table(cols, names=new_names)\n",
    "del featuretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = allfeats.to_pandas()\n",
    "\n",
    "df['target'] = meta_data.to_pandas()['target']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = df['target'].values\n",
    "y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7848, 72)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5886, 14)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100,input_dim=72,activation='relu'))\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "\n",
    "model.add(Dense(14,activation='sigmoid'))\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5886/5886 [==============================] - 0s 29us/step - loss: 1.7406 - acc: 0.3289\n",
      "Epoch 2/25\n",
      "5886/5886 [==============================] - 0s 22us/step - loss: 1.7751 - acc: 0.3265\n",
      "Epoch 3/25\n",
      "5886/5886 [==============================] - 0s 21us/step - loss: 1.9150 - acc: 0.2910\n",
      "Epoch 4/25\n",
      "5886/5886 [==============================] - 0s 20us/step - loss: 1.8249 - acc: 0.3090\n",
      "Epoch 5/25\n",
      "5886/5886 [==============================] - 0s 21us/step - loss: 1.7642 - acc: 0.3214\n",
      "Epoch 6/25\n",
      "5886/5886 [==============================] - 0s 20us/step - loss: 1.8750 - acc: 0.2903\n",
      "Epoch 7/25\n",
      "5886/5886 [==============================] - 0s 21us/step - loss: 1.7833 - acc: 0.3041\n",
      "Epoch 8/25\n",
      "5886/5886 [==============================] - 0s 23us/step - loss: 1.7399 - acc: 0.3070\n",
      "Epoch 9/25\n",
      "5886/5886 [==============================] - 0s 22us/step - loss: 1.7147 - acc: 0.3174\n",
      "Epoch 10/25\n",
      "5886/5886 [==============================] - 0s 21us/step - loss: 1.7054 - acc: 0.3236\n",
      "Epoch 11/25\n",
      "5886/5886 [==============================] - 0s 22us/step - loss: 1.7140 - acc: 0.3191\n",
      "Epoch 12/25\n",
      "5886/5886 [==============================] - 0s 22us/step - loss: 1.7099 - acc: 0.3203\n",
      "Epoch 13/25\n",
      "5886/5886 [==============================] - 0s 22us/step - loss: 1.6867 - acc: 0.3157\n",
      "Epoch 14/25\n",
      "5886/5886 [==============================] - 0s 22us/step - loss: 1.7311 - acc: 0.3045\n",
      "Epoch 15/25\n",
      "5886/5886 [==============================] - 0s 22us/step - loss: 1.6866 - acc: 0.3158\n",
      "Epoch 16/25\n",
      "5886/5886 [==============================] - 0s 24us/step - loss: 1.8666 - acc: 0.3107\n",
      "Epoch 17/25\n",
      "5886/5886 [==============================] - 0s 29us/step - loss: 1.8328 - acc: 0.3067\n",
      "Epoch 18/25\n",
      "5886/5886 [==============================] - 0s 24us/step - loss: 1.7617 - acc: 0.3177\n",
      "Epoch 19/25\n",
      "5886/5886 [==============================] - 0s 26us/step - loss: 1.7160 - acc: 0.3184\n",
      "Epoch 20/25\n",
      "5886/5886 [==============================] - 0s 23us/step - loss: 1.6823 - acc: 0.3243\n",
      "Epoch 21/25\n",
      "5886/5886 [==============================] - 0s 23us/step - loss: 1.6979 - acc: 0.3196\n",
      "Epoch 22/25\n",
      "5886/5886 [==============================] - 0s 24us/step - loss: 1.6579 - acc: 0.3272\n",
      "Epoch 23/25\n",
      "5886/5886 [==============================] - 0s 27us/step - loss: 1.6171 - acc: 0.3294\n",
      "Epoch 24/25\n",
      "5886/5886 [==============================] - 0s 25us/step - loss: 1.7674 - acc: 0.3163\n",
      "Epoch 25/25\n",
      "5886/5886 [==============================] - 0s 27us/step - loss: 1.6725 - acc: 0.3180\n",
      "1962/1962 [==============================] - 0s 73us/step\n",
      "\n",
      "acc: 29.92%\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(X_train),y_train,epochs=25,batch_size=100)\n",
    "scores=model.evaluate(np.array(X_test),y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dummies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-98b1755e1faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#how to convert dummies/predicted back to original for comparison.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dummies' is not defined"
     ]
    }
   ],
   "source": [
    "s2 = dummies.idxmax(axis=1)\n",
    "\n",
    "#how to convert dummies/predicted back to original for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plasticc_log_loss(y_true, y_pred, relative_class_weights=None):\n",
    "        \"\"\"\n",
    "        Implementation of weighted log loss used for the Kaggle challenge\n",
    "        \"\"\"\n",
    "        predictions = y_pred.copy()\n",
    "\n",
    "        # sanitize predictions\n",
    "        epsilon = sys.float_info.epsilon # this is machine dependent but essentially prevents log(0)\n",
    "        predictions = np.clip(predictions, epsilon, 1.0 - epsilon)\n",
    "        predictions = predictions / np.sum(predictions, axis=1)[:, np.newaxis]\n",
    "\n",
    "        predictions = np.log(predictions)\n",
    "        # multiplying the arrays is equivalent to a truth mask as y_true only contains zeros and ones\n",
    "        class_logloss = []\n",
    "        for i in range(predictions.shape[1]):\n",
    "            # average column wise log loss with truth mask applied\n",
    "            result = np.average(predictions[:, i][y_true[:, i] == 1])\n",
    "            class_logloss.append(result)\n",
    "        return -1 * np.average(class_logloss, weights=relative_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
